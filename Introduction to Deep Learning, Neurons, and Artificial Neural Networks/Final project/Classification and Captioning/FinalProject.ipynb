{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da0354af",
   "metadata": {},
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e490f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba79de",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33e3c0af",
   "metadata": {},
   "source": [
    "# Classification and Captioning Aircraft Damage Using Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d8f52",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d575c35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "585f2f02",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "import zipfile\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.applications import VGG16\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1272b5b5",
   "metadata": {},
   "source": [
    "# Set seed for reproducibility\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c4be3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95703ffd",
   "metadata": {},
   "source": [
    "#Set the batch size,epochs\n",
    "batch_size = 32\n",
    "n_epochs = 5\n",
    "img_rows, img_cols = 224, 224\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d268c63",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f626046a",
   "metadata": {},
   "source": [
    "import tarfile\n",
    "import urllib.request\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b26388",
   "metadata": {},
   "source": [
    "# URL of the tar file\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ZjXM4RKxlBK9__ZjHBLl5A/aircraft-damage-dataset-v1.tar\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a500b",
   "metadata": {},
   "source": [
    "# Define the path to save the file\n",
    "tar_filename = \"aircraft_damage_dataset_v1.tar\"\n",
    "extracted_folder = \"aircraft_damage_dataset_v1\"  # Folder where contents will be extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aeca6a",
   "metadata": {},
   "source": [
    "# Download the tar file\n",
    "urllib.request.urlretrieve(url, tar_filename)\n",
    "print(f\"Downloaded {tar_filename}. Extraction will begin now.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a29a300",
   "metadata": {},
   "source": [
    "# Check if the folder already exists\n",
    "if os.path.exists(extracted_folder):\n",
    "    print(f\"The folder '{extracted_folder}' already exists. Removing the existing folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0211c1e8",
   "metadata": {},
   "source": [
    "    # Remove the existing folder to avoid overwriting or duplication\n",
    "    shutil.rmtree(extracted_folder)\n",
    "    print(f\"Removed the existing folder: {extracted_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2c014",
   "metadata": {},
   "source": [
    "# Extract the contents of the tar file\n",
    "with tarfile.open(tar_filename, \"r\") as tar_ref:\n",
    "    tar_ref.extractall()  # This will extract to the current directory\n",
    "    print(f\"Extracted {tar_filename} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334c392c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7127f13d",
   "metadata": {},
   "source": [
    "# Define directories for train, test, and validation splits\n",
    "extract_path = \"aircraft_damage_dataset_v1\"\n",
    "train_dir = os.path.join(extract_path, 'train')\n",
    "test_dir = os.path.join(extract_path, 'test')\n",
    "valid_dir = os.path.join(extract_path, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d1ea5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e79c12b6",
   "metadata": {},
   "source": [
    "# Create ImageDataGenerators to preprocess the data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6947f2ec",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6da32c2",
   "metadata": {},
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_rows, img_cols),   # Resize images to the size VGG16 expects\n",
    "    batch_size=batch_size,\n",
    "    seed = seed_value,\n",
    "    class_mode='binary',\n",
    "    shuffle=True # Binary classification: dent vs crack\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7d5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e12dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6814cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775136ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9162fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59364440",
   "metadata": {},
   "source": [
    "# Task 1: Create a valid_generator using the valid_datagen object\n",
    "# Please use the following parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5727702",
   "metadata": {},
   "source": [
    "# directory should be set to valid_dir.\n",
    "# class_mode should be set to 'binary'.\n",
    "# seed should be set to seed_value.\n",
    "# batch_size should be set to batch_size.\n",
    "# shuffle should be set to False.\n",
    "# target_size should be set to (img_rows, img_cols).\n",
    "# Hint: the format should be like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a633b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3421d41",
   "metadata": {},
   "source": [
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory=valid_dir,\n",
    "    class_mode='binary',\n",
    "    seed=seed_value,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    target_size=(img_rows, img_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28332337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1fd6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45c448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4071b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc7c368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b8e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cafbee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28fa08bf",
   "metadata": {},
   "source": [
    "# Task 2: Create a test_generator using the test_datagen object\n",
    "# Please use the following parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fd5ac4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# directory should be set to test_dir.\n",
    "# class_mode should be set to 'binary'.\n",
    "# seed should be set to seed_value.\n",
    "# batch_size should be set to batch_size.\n",
    "# shuffle should be set to False.\n",
    "# target_size should be set to (img_rows, img_cols).\n",
    "# Hint: The format should be like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0cfc58",
   "metadata": {},
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    class_mode='binary',\n",
    "    seed=seed_value,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    target_size=(img_rows, img_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd708bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393c25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c061a23c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e825ddb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c6351e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d347495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3134935d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689bb2a1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "013b4ef9",
   "metadata": {},
   "source": [
    "# Task 3: Load the pre-trained model VGG16\n",
    "# Set weights='imagenet',include_top=False,input_shape=(img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee4b9e",
   "metadata": {},
   "source": [
    "# Hint: The format should be like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d9ee82",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# base_model = VGG16(weights= , include_top= , input_shape=)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5eed21",
   "metadata": {},
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c29a8c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b69ac5d",
   "metadata": {},
   "source": [
    "output = base_model.layers[-1].output\n",
    "output = keras.layers.Flatten()(output)\n",
    "base_model = Model(base_model.input, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a9607f",
   "metadata": {},
   "source": [
    "# Freeze the base VGG16 model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973aed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74b61b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1341125e",
   "metadata": {},
   "source": [
    "    # Build the custom model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a0f862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed2045b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ed7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba27d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e1eefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70586ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe11874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e385765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6030307c",
   "metadata": {},
   "source": [
    "# Task 4: Compile the model\n",
    "# You will compile the model using the following parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0602be9",
   "metadata": {},
   "source": [
    "# loss: 'binary_crossentropy'.\n",
    "# optimizer: =Adam(learning_rate=0.0001).\n",
    "# metrics: ['accuracy'].\n",
    "# Hint: Use model.compile() to compile the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4b0cf",
   "metadata": {},
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48681f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f1532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbb9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b4fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f6e1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af930f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a8916e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcbd87d3",
   "metadata": {},
   "source": [
    "# Task 5: Model Training\n",
    "# Now that the model is compiled, you can train it using the .fit() method. This step involves passing in the training and validation datasets along with the number of epochs you want to train the model for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51aa13a",
   "metadata": {},
   "source": [
    "# You will train the model using the following parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81633e3",
   "metadata": {},
   "source": [
    "# train_data: train_generator\n",
    "# epochs: n_epochs\n",
    "# validation_data: valid_generator\n",
    "# Hint: Use model.fit() to train the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ad4eb",
   "metadata": {},
   "source": [
    "history = model.fit(\n",
    "    train_generator,            # Təlim üçün generator\n",
    "    epochs=n_epochs,            # Epoch sayı (əvvəldən təyin etdiniz)\n",
    "    validation_data=valid_generator  # Doğrulama generatoru\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bebd936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3efbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75519c6a",
   "metadata": {},
   "source": [
    "# Access the training history\n",
    "train_history = model.history.history  # After training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7782c563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95fbd5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "081a03ea",
   "metadata": {},
   "source": [
    "# Plot the loss for both training and validation\n",
    "plt.title(\"Training Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(train_history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b60a9",
   "metadata": {},
   "source": [
    "plt.title(\"Validation Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(train_history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e4c8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248098f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66bdeca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15003335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6fcb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81053ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "176401c7",
   "metadata": {},
   "source": [
    "# Task 6: Plot accuracy curves for training and validation sets\n",
    "# Hint: Similar to the loss curves. Use plt.plot() to plot the accuracy curves for training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f65a49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8729812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67bd9ff7",
   "metadata": {},
   "source": [
    "# Əyriləri çəkirik\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(train_history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(train_history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a206524b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0034f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8de4ba9f",
   "metadata": {},
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e213c2",
   "metadata": {},
   "source": [
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5706c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fe55f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6051b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a3a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0504248c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4010f2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1552d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f925362b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b53571bb",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e9881",
   "metadata": {},
   "source": [
    "# Function to plot a single image and its prediction\n",
    "def plot_image_with_title(image, model, true_label, predicted_label, class_names):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666db799",
   "metadata": {},
   "source": [
    "    # Convert labels from one-hot to class indices if needed, but for binary labels it's just 0 or 1\n",
    "    true_label_name = class_names[true_label]  # Labels are already in class indices\n",
    "    pred_label_name = class_names[predicted_label]  # Predictions are 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f088fa",
   "metadata": {},
   "source": [
    "    plt.title(f\"True: {true_label_name}\\nPred: {pred_label_name}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f37b64",
   "metadata": {},
   "source": [
    "# Function to test the model with images from the test set\n",
    "def test_model_on_image(test_generator, model, index_to_plot=0):\n",
    "    # Get a batch of images and labels from the test generator\n",
    "    test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d4a2cb",
   "metadata": {},
   "source": [
    "    # Make predictions on the batch\n",
    "    predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce56909",
   "metadata": {},
   "source": [
    "    # In binary classification, predictions are probabilities (float). Convert to binary (0 or 1)\n",
    "    predicted_classes = (predictions > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba3f059",
   "metadata": {},
   "source": [
    "    # Get the class indices from the test generator and invert them to get class names\n",
    "    class_indices = test_generator.class_indices\n",
    "    class_names = {v: k for k, v in class_indices.items()}  # Invert the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869beb75",
   "metadata": {},
   "source": [
    "    # Specify the image to display based on the index\n",
    "    image_to_plot = test_images[index_to_plot]\n",
    "    true_label = test_labels[index_to_plot]\n",
    "    predicted_label = predicted_classes[index_to_plot]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55a7f8e",
   "metadata": {},
   "source": [
    "    # Plot the selected image with its true and predicted labels\n",
    "    plot_image_with_title(image=image_to_plot, model=model, true_label=true_label, predicted_label=predicted_label, class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1620fe65",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "776a9afe",
   "metadata": {},
   "source": [
    "test_model_on_image(test_generator, model, index_to_plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41406474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd66c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c1467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d87d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9577f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16757653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2a070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c8d8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a22e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c90fbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89412cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07fc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae85220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322d4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2316f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95eeca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5791b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8528549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c34e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35360496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a8a7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2b78d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "191c5f96",
   "metadata": {},
   "source": [
    "Part 2: Image Captioning and Summarization using BLIP Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa49802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the required libraries\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefddfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pretrained BLIP processor and model:\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30be5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3eedc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d3c0c3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlipCaptionSummaryLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, processor, model, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the custom Keras layer with the BLIP processor and model.\n",
    "\n",
    "        Args:\n",
    "            processor: The BLIP processor for preparing inputs for the model.\n",
    "            model: The BLIP model for generating captions or summaries.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "\n",
    "    def call(self, image_path, task):\n",
    "        # Use tf.py_function to run the custom image processing and text generation\n",
    "        return tf.py_function(self.process_image, [image_path, task], tf.string)\n",
    "\n",
    "    def process_image(self, image_path, task):\n",
    "        \"\"\"\n",
    "        Perform image loading, preprocessing, and text generation.\n",
    "\n",
    "        Args:\n",
    "            image_path: Path to the image file as a string.\n",
    "            task: The type of task (\"caption\" or \"summary\").\n",
    "\n",
    "        Returns:\n",
    "            The generated caption or summary as a string.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Decode the image path from the TensorFlow tensor to a Python string\n",
    "            image_path_str = image_path.numpy().decode(\"utf-8\")\n",
    "\n",
    "            # Open the image using PIL and convert it to RGB format\n",
    "            image = Image.open(image_path_str).convert(\"RGB\")\n",
    "\n",
    "            # Set the appropriate prompt based on the task\n",
    "            if task.numpy().decode(\"utf-8\") == \"caption\":\n",
    "                prompt = \"This is a picture of\"  # Modify prompt for more natural output\n",
    "            else:\n",
    "                prompt = \"This is a detailed photo showing\"  # Modify for summary\n",
    "\n",
    "            # Prepare inputs for the BLIP model\n",
    "            inputs = self.processor(images=image, text=prompt, return_tensors=\"pt\")\n",
    "\n",
    "            # Generate text output using the BLIP model\n",
    "            output = self.model.generate(**inputs)\n",
    "\n",
    "            # Decode the output into a readable string\n",
    "            result = self.processor.decode(output[0], skip_special_tokens=True)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            # Handle errors during image processing or text generation\n",
    "            print(f\"Error: {e}\")\n",
    "            return \"Error processing image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa20164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce460f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0e906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b167b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a2868c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e129e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0475bb9d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ef8d440",
   "metadata": {},
   "source": [
    "Task 8: Implement a Helper Function to Use the Custom Keras Layer\n",
    "In this task, you will implement a helper function generate_text that utilizes the custom BlipCaptionSummaryLayer Keras layer to generate captions or summaries for a given image. The function will accept an image path and a task type (caption or summary), process the image using the BLIP model, and return the generated text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79781d6",
   "metadata": {},
   "source": [
    "Steps:\n",
    "Create the Helper Function generate_text:\n",
    "The function will accept following parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56409a76",
   "metadata": {},
   "source": [
    "image_path: The path to the image file (in tensor format).\n",
    "task: The type of task to perform, which can either be \"caption\" or \"summary\" (in tensor format).\n",
    "Inside the function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcddb6ad",
   "metadata": {},
   "source": [
    "Create an instance(blip_layer) of the BlipCaptionSummaryLayer.\n",
    "Call this layer with the provided image path and task type.\n",
    "Return the generated caption or summary as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea9f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e347e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa9275d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d92c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(image_path, task):\n",
    "    # BLIP processor və modeli əvvəlcədən yüklənmiş olmalıdır\n",
    "    blip_layer = BlipCaptionSummaryLayer(processor, model)\n",
    "\n",
    "    # Tensor şəklinə sal\n",
    "    image_path_tensor = tf.convert_to_tensor(image_path, dtype=tf.string)\n",
    "    task_tensor = tf.convert_to_tensor(task, dtype=tf.string)\n",
    "\n",
    "    # Layer-ə ötür və nəticəni qaytar\n",
    "    return blip_layer(image_path_tensor, task_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58945169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to an example image \n",
    "image_path = tf.constant(\"aircraft_damage_dataset_v1/test/dent/144_10_JPG_jpg.rf.4d008cc33e217c1606b76585469d626b.jpg\")  # actual path of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900cf7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a caption for the image\n",
    "caption = generate_text(image_path, tf.constant(\"caption\"))\n",
    "# Decode and print the generated caption\n",
    "print(\"Caption:\", caption.numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c8011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a summary for the image\n",
    "summary = generate_text(image_path, tf.constant(\"summary\"))\n",
    "# Decode and print the generated summary\n",
    "print(\"Summary:\", summary.numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67579d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21208de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf8d1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe913701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818a025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4e3aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a4a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca48f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797af0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db56cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771f483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc14723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to an example image \n",
    "image_path = tf.constant(\"aircraft_damage_dataset_v1/test/dent/144_10_JPG_jpg.rf.4d008cc33e217c1606b76585469d626b.jpg\")  # actual path of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1664aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a caption for the image\n",
    "caption = generate_text(image_path, tf.constant(\"caption\"))\n",
    "# Decode and print the generated caption\n",
    "print(\"Caption:\", caption.numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcc2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a summary for the image\n",
    "summary = generate_text(image_path, tf.constant(\"summary\"))\n",
    "# Decode and print the generated summary\n",
    "print(\"Summary:\", summary.numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb51fc7a",
   "metadata": {},
   "source": [
    "Task 9: Generate a caption for an image using the using BLIP pretrained model\n",
    "Use the image_path variable given below to load the image. Run the cell to before proceeding to next step.\n",
    "Use the generate_text function to generate a caption for the image.\n",
    "Use the example given in 2.2 Generating Captions and Summaries for this task\n",
    "Note: Generated captions may not always be accurate, as the model is limited by its training data and may not fully understand new or specific images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bc0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Şəkli göstərin (artıq göstərmisiniz)\n",
    "img = plt.imread(image_url)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206fa7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Şəkilin yolu tensor formatında (verilmişdir)\n",
    "image_path = tf.constant(\"aircraft_damage_dataset_v1/test/dent/149_22_JPG_jpg.rf.4899cbb6f4aad9588fa3811bb886c34d.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10eb980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_text funksiyasını istifadə edərək caption yaradın\n",
    "caption = generate_text(image_path, \"caption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3459f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generated Caption:\", caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b7a34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c7a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374730a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c7fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6105bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393c021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7872a485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e983ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbda47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b3bacb4",
   "metadata": {},
   "source": [
    "Task 10: Generate a summary of an image using BLIP pretrained model\n",
    "Use the image_path variable given below to load the image. Run the cell before proceeding to next step.\n",
    "Use the generate_text function to generate a caption for the image.\n",
    "Use the example given in 2.2 Generating Captions and Summaries for this task\n",
    "Note: Generated summary may not always be accurate, as the model is limited by its training data and may not fully understand new or specific images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626211ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dfeb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Şəkilin yolu tensor formatında (verilmişdir)\n",
    "image_path = tf.constant(\"aircraft_damage_dataset_v1/test/dent/149_22_JPG_jpg.rf.4899cbb6f4aad9588fa3811bb886c34d.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196cd5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_text funksiyasını istifadə edərək summary yaradın\n",
    "summary = generate_text(image_path, tf.constant(\"summary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf0886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary-ni çap edin\n",
    "print(\"Generated Summary:\", summary.numpy().decode(\"utf-8\"))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
